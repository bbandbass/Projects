{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1y78XukmNnOofaPeYUFbYhdKgijNBBjvn",
      "authorship_tag": "ABX9TyOfHK9I6suHejehiO0874cg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bbandbass/Projects/blob/main/skip_gram_implementation2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "eS0gkh8tstuB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "window_size = 2  # context words로 왼쪽으로 2 단어, 오른쪽으로 2 단어\n",
        "\n",
        "sentence = \"\"\"\n",
        "Regrets, I've had a few.\n",
        "But then again, too few to mention.\n",
        "I did what I had to do.\n",
        "And saw it through without exemption.\n",
        "I planned each charted course.\n",
        "Each careful step along the byway.\n",
        "And more, much more than this, I did it my way.\n",
        "\"\"\"\n",
        "\n",
        "words = sentence.split()\n",
        "\n",
        "vocab = set(words)\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "word_to_idx = {word:idx for idx, word in enumerate(vocab)}\n",
        "idx_to_word = {idx:word for idx, word in enumerate(vocab)}\n",
        "\n",
        "data = []\n",
        "\n",
        "# context words와 centor word \n",
        "for i in range(window_size, len(words) - window_size):\n",
        "  context = [words[i - window_size : i], words[i + 1 : i + window_size + 1]]\n",
        "  context = context[0] + context[1]\n",
        "  center = words[i]\n",
        "  data.append((context, center))"
      ],
      "metadata": {
        "id": "MAi8riqA1a_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwmZtvXgm_Vy",
        "outputId": "fb1b9872-ddd4-42c7-ab61-7a0ca2fb1932"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(['Regrets,', \"I've\", 'a', 'few.'], 'had'),\n",
              " ([\"I've\", 'had', 'few.', 'But'], 'a'),\n",
              " (['had', 'a', 'But', 'then'], 'few.'),\n",
              " (['a', 'few.', 'then', 'again,'], 'But'),\n",
              " (['few.', 'But', 'again,', 'too'], 'then'),\n",
              " (['But', 'then', 'too', 'few'], 'again,'),\n",
              " (['then', 'again,', 'few', 'to'], 'too'),\n",
              " (['again,', 'too', 'to', 'mention.'], 'few'),\n",
              " (['too', 'few', 'mention.', 'I'], 'to'),\n",
              " (['few', 'to', 'I', 'did'], 'mention.'),\n",
              " (['to', 'mention.', 'did', 'what'], 'I'),\n",
              " (['mention.', 'I', 'what', 'I'], 'did'),\n",
              " (['I', 'did', 'I', 'had'], 'what'),\n",
              " (['did', 'what', 'had', 'to'], 'I'),\n",
              " (['what', 'I', 'to', 'do.'], 'had'),\n",
              " (['I', 'had', 'do.', 'And'], 'to'),\n",
              " (['had', 'to', 'And', 'saw'], 'do.'),\n",
              " (['to', 'do.', 'saw', 'it'], 'And'),\n",
              " (['do.', 'And', 'it', 'through'], 'saw'),\n",
              " (['And', 'saw', 'through', 'without'], 'it'),\n",
              " (['saw', 'it', 'without', 'exemption.'], 'through'),\n",
              " (['it', 'through', 'exemption.', 'I'], 'without'),\n",
              " (['through', 'without', 'I', 'planned'], 'exemption.'),\n",
              " (['without', 'exemption.', 'planned', 'each'], 'I'),\n",
              " (['exemption.', 'I', 'each', 'charted'], 'planned'),\n",
              " (['I', 'planned', 'charted', 'course.'], 'each'),\n",
              " (['planned', 'each', 'course.', 'Each'], 'charted'),\n",
              " (['each', 'charted', 'Each', 'careful'], 'course.'),\n",
              " (['charted', 'course.', 'careful', 'step'], 'Each'),\n",
              " (['course.', 'Each', 'step', 'along'], 'careful'),\n",
              " (['Each', 'careful', 'along', 'the'], 'step'),\n",
              " (['careful', 'step', 'the', 'byway.'], 'along'),\n",
              " (['step', 'along', 'byway.', 'And'], 'the'),\n",
              " (['along', 'the', 'And', 'more,'], 'byway.'),\n",
              " (['the', 'byway.', 'more,', 'much'], 'And'),\n",
              " (['byway.', 'And', 'much', 'more'], 'more,'),\n",
              " (['And', 'more,', 'more', 'than'], 'much'),\n",
              " (['more,', 'much', 'than', 'this,'], 'more'),\n",
              " (['much', 'more', 'this,', 'I'], 'than'),\n",
              " (['more', 'than', 'I', 'did'], 'this,'),\n",
              " (['than', 'this,', 'did', 'it'], 'I'),\n",
              " (['this,', 'I', 'it', 'my'], 'did'),\n",
              " (['I', 'did', 'my', 'way.'], 'it')]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def make_context_vector(context, word_to_idx):\n",
        "    context_index = [word_to_idx[w] for w in context]\n",
        "    return torch.tensor(context_index, dtype = torch.long)"
      ],
      "metadata": {
        "id": "IZxhMSoPYxcn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_center_vector(center, word_to_idx):\n",
        "  return torch.tensor(word_to_idx[center], dtype = torch.long)"
      ],
      "metadata": {
        "id": "J9uy8qQbvrjw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Skip-gram2\n"
      ],
      "metadata": {
        "id": "F2OnGawDbVze"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SkipGram2(nn.Module):\n",
        "  def __init__(self, vocab_size, projection_size, window_size):\n",
        "    super(SkipGram2, self).__init__()\n",
        "    self.projection = nn.Embedding(vocab_size, projection_size)\n",
        "    self.linear = nn.ModuleList()\n",
        "    for i in range(2 * window_size):\n",
        "      self.linear.append(nn.Linear(projection_size, vocab_size))\n",
        "    self.activation = nn.LogSoftmax(dim = 0)\n",
        "\n",
        "  def forward(self, input):\n",
        "    \n",
        "    y_hat = []\n",
        "    projection = self.projection(input)\n",
        "    for i in range(len(self.linear)):\n",
        "      output = self.linear[i](projection)\n",
        "      y_hat.append(self.activation(output))\n",
        "    \n",
        "    return y_hat"
      ],
      "metadata": {
        "id": "F0qyk7N0J0-P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "skipgram2 = SkipGram2(vocab_size, 500, 2)\n",
        "\n",
        "criterion = nn.NLLLoss()\n",
        "optimizer = torch.optim.SGD(skipgram2.parameters(), lr = 0.01)"
      ],
      "metadata": {
        "id": "z8bAXKSpRG3v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "skipgram2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AfeU-T0PWKHw",
        "outputId": "c49de242-3210-4bab-dcd8-b45ea75c2061"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SkipGram2(\n",
              "  (projection): Embedding(39, 500)\n",
              "  (linear): ModuleList(\n",
              "    (0): Linear(in_features=500, out_features=39, bias=True)\n",
              "    (1): Linear(in_features=500, out_features=39, bias=True)\n",
              "    (2): Linear(in_features=500, out_features=39, bias=True)\n",
              "    (3): Linear(in_features=500, out_features=39, bias=True)\n",
              "  )\n",
              "  (activation): LogSoftmax(dim=0)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "center_vector"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8erh379_pYL",
        "outputId": "1a74541f-61aa-45e1-d3e7-ad27244fe5d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(30)"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(5000):\n",
        "  \n",
        "  loss = 0\n",
        "\n",
        "  for context, center in data:\n",
        "    \n",
        "    target_vectors = make_context_vector(context, word_to_idx)\n",
        "    # print(target_vectors)\n",
        "    # print(target_vectors.dim())\n",
        "    center_vector = make_center_vector(center, word_to_idx)\n",
        "    # print(center_vector.dim())\n",
        "    y_hat = skipgram2(center_vector)\n",
        "    for i in range(len(target_vectors)):\n",
        "      loss += criterion(y_hat[i], target_vectors[i])\n",
        "    \n",
        "  if (epoch + 1) % 10 == 0:\n",
        "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.6f}'.format(loss))\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()"
      ],
      "metadata": {
        "id": "y7qWykPaRG3w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(context)\n",
        "print(center)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee96af72-2fda-4166-96c8-a1e3ace525e3",
        "id": "j-XZJtQ4HmVT"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['I', 'did', 'my', 'way.']\n",
            "it\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for_test = skipgram2(center_vector)"
      ],
      "metadata": {
        "id": "tOrb-kLHHmVU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print([idx_to_word[torch.argmax(i).item()] for i in for_test])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "730586ca-83c1-4c84-aaf1-f8182f10668c",
        "id": "KPkMxKygHmVV"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['I', 'did', 'through', 'way.']\n"
          ]
        }
      ]
    }
  ]
}