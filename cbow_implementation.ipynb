{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1y78XukmNnOofaPeYUFbYhdKgijNBBjvn",
      "authorship_tag": "ABX9TyOIHuaYBqFQnf+K/h3VsP9b",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bbandbass/Projects/blob/main/cbow_implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "eS0gkh8tstuB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "window_size = 2  # context words로 왼쪽으로 2 단어, 오른쪽으로 2 단어\n",
        "\n",
        "sentence = \"\"\"\n",
        "Regrets, I've had a few.\n",
        "But then again, too few to mention.\n",
        "I did what I had to do.\n",
        "And saw it through without exemption.\n",
        "I planned each charted course.\n",
        "Each careful step along the byway.\n",
        "And more, much more than this, I did it my way.\n",
        "\"\"\"\n",
        "\n",
        "words = sentence.split()\n",
        "\n",
        "vocab = set(words)\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "word_to_idx = {word:idx for idx, word in enumerate(vocab)}\n",
        "idx_to_word = {idx:word for idx, word in enumerate(vocab)}\n",
        "\n",
        "data = []\n",
        "\n",
        "# context words와 centor word \n",
        "for i in range(window_size, len(words) - window_size):\n",
        "  context = [words[i - window_size : i], words[i + 1 : i + window_size + 1]]\n",
        "  context = context[0] + context[1]\n",
        "  center = words[i]\n",
        "  data.append((context, center))"
      ],
      "metadata": {
        "id": "MAi8riqA1a_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwmZtvXgm_Vy",
        "outputId": "fb1b9872-ddd4-42c7-ab61-7a0ca2fb1932"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(['Regrets,', \"I've\", 'a', 'few.'], 'had'),\n",
              " ([\"I've\", 'had', 'few.', 'But'], 'a'),\n",
              " (['had', 'a', 'But', 'then'], 'few.'),\n",
              " (['a', 'few.', 'then', 'again,'], 'But'),\n",
              " (['few.', 'But', 'again,', 'too'], 'then'),\n",
              " (['But', 'then', 'too', 'few'], 'again,'),\n",
              " (['then', 'again,', 'few', 'to'], 'too'),\n",
              " (['again,', 'too', 'to', 'mention.'], 'few'),\n",
              " (['too', 'few', 'mention.', 'I'], 'to'),\n",
              " (['few', 'to', 'I', 'did'], 'mention.'),\n",
              " (['to', 'mention.', 'did', 'what'], 'I'),\n",
              " (['mention.', 'I', 'what', 'I'], 'did'),\n",
              " (['I', 'did', 'I', 'had'], 'what'),\n",
              " (['did', 'what', 'had', 'to'], 'I'),\n",
              " (['what', 'I', 'to', 'do.'], 'had'),\n",
              " (['I', 'had', 'do.', 'And'], 'to'),\n",
              " (['had', 'to', 'And', 'saw'], 'do.'),\n",
              " (['to', 'do.', 'saw', 'it'], 'And'),\n",
              " (['do.', 'And', 'it', 'through'], 'saw'),\n",
              " (['And', 'saw', 'through', 'without'], 'it'),\n",
              " (['saw', 'it', 'without', 'exemption.'], 'through'),\n",
              " (['it', 'through', 'exemption.', 'I'], 'without'),\n",
              " (['through', 'without', 'I', 'planned'], 'exemption.'),\n",
              " (['without', 'exemption.', 'planned', 'each'], 'I'),\n",
              " (['exemption.', 'I', 'each', 'charted'], 'planned'),\n",
              " (['I', 'planned', 'charted', 'course.'], 'each'),\n",
              " (['planned', 'each', 'course.', 'Each'], 'charted'),\n",
              " (['each', 'charted', 'Each', 'careful'], 'course.'),\n",
              " (['charted', 'course.', 'careful', 'step'], 'Each'),\n",
              " (['course.', 'Each', 'step', 'along'], 'careful'),\n",
              " (['Each', 'careful', 'along', 'the'], 'step'),\n",
              " (['careful', 'step', 'the', 'byway.'], 'along'),\n",
              " (['step', 'along', 'byway.', 'And'], 'the'),\n",
              " (['along', 'the', 'And', 'more,'], 'byway.'),\n",
              " (['the', 'byway.', 'more,', 'much'], 'And'),\n",
              " (['byway.', 'And', 'much', 'more'], 'more,'),\n",
              " (['And', 'more,', 'more', 'than'], 'much'),\n",
              " (['more,', 'much', 'than', 'this,'], 'more'),\n",
              " (['much', 'more', 'this,', 'I'], 'than'),\n",
              " (['more', 'than', 'I', 'did'], 'this,'),\n",
              " (['than', 'this,', 'did', 'it'], 'I'),\n",
              " (['this,', 'I', 'it', 'my'], 'did'),\n",
              " (['I', 'did', 'my', 'way.'], 'it')]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def make_context_vector(context, word_to_idx):\n",
        "    context_index = [word_to_idx[w] for w in context]\n",
        "    return torch.tensor(context_index, dtype = torch.long)"
      ],
      "metadata": {
        "id": "IZxhMSoPYxcn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_center_vector(center, word_to_idx):\n",
        "  return torch.tensor(word_to_idx[center], dtype = torch.long)"
      ],
      "metadata": {
        "id": "J9uy8qQbvrjw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CBOW"
      ],
      "metadata": {
        "id": "tVrRKOMsJxWG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "prry4i8ilp0S"
      },
      "outputs": [],
      "source": [
        "class CBOW(nn.Module):\n",
        "  def __init__(self, vocab_size, projection_size):\n",
        "    super(CBOW, self).__init__()\n",
        "    self.projection = nn.Embedding(vocab_size, projection_size)\n",
        "    self.linear = nn.Linear(projection_size, vocab_size)\n",
        "\n",
        "  def forward(self, input):\n",
        "    \n",
        "    projection = self.projection(input)\n",
        "    projection_mean = projection.mean(axis = 0)\n",
        "    output = self.linear(projection_mean)\n",
        "\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cbow = CBOW(vocab_size, 500)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(cbow.parameters(), lr = 0.01)"
      ],
      "metadata": {
        "id": "DXBqH7WBmbrc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(5000):\n",
        "  \n",
        "  loss = 0\n",
        "\n",
        "  for context, center in data:\n",
        "    \n",
        "    context_vector = make_context_vector(context, word_to_idx)\n",
        "    center_vector = make_center_vector(center, word_to_idx)\n",
        "    y_hat = cbow(context_vector)\n",
        "    loss += criterion(y_hat, center_vector)\n",
        "    \n",
        "  \n",
        "  if (epoch + 1) % 10 == 0:\n",
        "    print('Epoch:', '%04d' % (epoch + 1), 'loss =', '{:.6f}'.format(loss))\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()"
      ],
      "metadata": {
        "id": "gnf6NILvrBih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(context)\n",
        "print(center)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4l_e7Qczjsm",
        "outputId": "7deeee39-ffbb-4cf1-882d-250df8180e56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['I', 'did', 'my', 'way.']\n",
            "it\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for_test = cbow(context_vector)"
      ],
      "metadata": {
        "id": "8qPY05Qjwc3B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print({idx_to_word[torch.argmax(for_test).item()]})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vyO5gOysyGg1",
        "outputId": "85818438-9ca4-4706-d005-1ef57a666ea1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'it'}\n"
          ]
        }
      ]
    }
  ]
}